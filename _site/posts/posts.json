[
  {
    "path": "posts/2021-02-02-friedmanarticle/",
    "title": "Friedman's Defense of Homo Economicus",
    "description": "The Methodology of Positive Economics",
    "author": [
      {
        "name": "Amit Gandhi",
        "url": {}
      }
    ],
    "date": "2021-02-02",
    "categories": [
      "Homo Economicus",
      "positive economics"
    ],
    "contents": "\nFriedman‚Äôs essay on the Methodology of Positive Economics written in 1953 is a classic exposition of the economic approach to studying problems. It forces us to contend with the the empirical interpretation of Homo Economicus and its role in the normative vs positive applications of economic theory.\nMilton Friedman\n\nBorn in 1912 in New York City\nBA Rutgers University(1932) MA University of Chicago \\(1933\\) PhD Columbia University \\(1946\\)\nProfessor at University of Chicago \\(1946\\-1977\\)\nFellow at the Hoover Institution,at StanfordUniversity \\(1977\\-\\)\nMentors:Arthur Burns, Wesley Mitchell, Jacob Viner, Frank Knight\n1976:Nobel Memorial Prize in Economics\nInfluence:in economics - New Classical Macroeconomics, in policy - Ronald Regan and, Margaret Thatcher \\(1980s\\)\nControversy:lecture in Chile in 1975\nHe died in San Francisco in 2006\nScientific contribution\nStatistics\nFriedman non-parametric tests JASA 1937, JASA 1939, AMS 1940\nMethodology\n‚ÄúThe Methodology of Positive Economics‚Äù in Essays in Positive Economics \\(1953\\)\nConsumption\nA Theory of the Consumption Function \\(1957\\)\nMonetary theory, history and policy\nA Monetary History of the United States, 1867-1960 with A. Schwartz, 1963;\n‚ÄúThe Quantity Theory of Money:A Restatement‚Äù, in Studies in the Quantity Theory of Money ed.M.Friedman,1956;\n‚ÄúThe Role of Monetary Policy‚Äù, (AER 1968); ‚ÄúA Theoretical Framework for Monetary Analysis‚Äù ( JPE 1970)\nBusiness cycles and inflation\n‚ÄúMoney and business cycles‚Äù with A. Schwartz (RES,1963)\nMonetary Trends in the US and the UK with A. Schwartz,1982;\n‚ÄúInflation and Unemployment‚Äù (JPE 1977)\nIdeology, Pop\nCapitialism and Freedom (1962)\nFree to Choose with R Friedman, 1980)\nThe ‚ÄúNormative‚Äù Friedman\nLater in Freidman‚Äôs career, he became a popuar voice for economics in the mainstream media, and would engage with large and broad audienecs ‚Äúhead-on‚Äù for live policy debates. He thus took a normative view of policy - what types of policies should be enacted - based on his understanding of the positive predictions from economic theory.\nIn addition to being a towering intellect, he was a fierce debater and orator of economics. Here is a famous discussion he gave on the power of prices in a market economy as a means to efficiently coordinated the multitude of economic decisions that are linked together in an economy.\n\n\n\n\n\n\n\nWe thus see his normative leanings towards market as drivers of overall efficiency - a topic which continues today to be hotly debated. In this normative stance, Homo Economicus was a means to an end - a way to reach conclusions about the effect of economic policies\nThe revival of the homo economicus\nIdea of homo economicus (Mill 1836; Robbins 1932)\nKeynes (1936): alternative views:\nanimal spirits\nfundamental psychological law\n\nFriedman:revivalof rational behaviour in economics\nconcept of ‚Äúpermanent income‚Äù in consumption\nrejection of permanent trade-off between inflationa ndunemployment due to expectations of future inflation\n\nMarshallian methodology\nFriedman was not as radical as the New Classical Macroeconomics (Lucas,Sargent):\n-rejection of Rational Expectation Hypothesis\nMarshallian vs.¬†Walrasian methodology\nWalrasian perspective: general equilibrium and complete micro-foundation in individual optimization; secondary role of empirical evidence\nMarshallian perspective: partial equilibrium\ntheory as ‚Äúan engine for the discovery of concrete truth‚Äù (Marshall1885)\nimportance of empirical economics\n\nFriedman considered himself a Marshallian\nF. 53\n‚ÄúThe Methodology of Positive Economics‚Äù\nA forceful, careful, and heavily influential essay on the meaning of the methodology of economics.\n CHICAGO. ECONOMICS 300A. CORE THEORY. GARY BECKER, 1956 \n\n_______________\n Economics 300A   Autumn 1956   Reading Assignments by G. Becker \nNOTES:\n1) A knowledge of the material in George Stigler,  A Theory of Price  or in Kenneth Boulding ,  Economic Analysis  , is a prerequisite.  2) Readings marked with an asterisk \\(*\\) are recommended, not required.\n I. INTRODUCTION \nFriedman, M.,  Lecture Notes  , pp. 1-16. Knight, F. H.,  The Economic Organization  , pp. 1-37. Friedman, Milton, ‚ÄúThe New Methodology of Positive Economics,‚Äù in  Essays in Positive Economics  . *Hayek, F. A., ‚ÄúThe Use of Knowledge in Society,‚Äù  American Economic Review  , September 1945, reprinted in  Individualism and Economic Order  . *Keynes, J. N.,  The Scope and Method of Political Economy  , pp. 1-83.\n II. DEMAND ANALYSIS \nMarshall, A.,  Principles of Economics  , Book III, chs . 2-4; Book V, chs . 1-2.\nF.‚Äôs enemies\n1946-1953: controversy on the ‚Äúmarginalist‚Äù theory of the firm\nHall and Hitch (1939): ‚ÄúPrice Theory and Business Behaviour‚Äù, Oxford Economic Papers\nsurvey on how prices emerged within firms\nrules of thumb inconsistent with the hypothesis of maximization of expected profits\npsychological mechanisms different from model‚Äôs mechanism: false assumptions\n\nThe Rise of Chamberlainian and Walrasian Economics: Monopolistic Competition and General Equilibrium.\nFriedman is feeling the Marshallian approach under attack from multiple fronts. As his 1974 self revealed - how do you respond?\n‚ÄúYou cannot be sure that you are right unless you understand the arguments against your views better than your opponents do.‚Äù\nThe Methodology of Positive Economics (1953)\nOpening line:\nIn his admirable book on The Scope and Method of Political Economy, John Neville Keynes distinguishes among ‚Äúa  positive  science . . . a body of systematized knowledge concerning what is;  a   normative  or regulative science ... a body of systematized knowledge discussing criteria of what ought to be . . . ; an  art  ... a system of rules for the attainment of a given end\"; comments that ‚Äúconfusion between them is common and has been the source of many mischievous errors\"; and urges the importance of ‚Äúrecognizing a distinct positive science of political economy‚Äù.\nHe thus raised the positive-normative distinction, which he continues to discuss\n\nNormative economics and the art of economics, on the other hand, cannot be independent of positive economics. Any policy conclusion necessarily rests on a prediction about the consequences of doing one thing rather than another, a prediction that must be based ‚Äì implicitly or explicitly - on positive economics. There is not, of course, a one-to-one relation between policy conclusions and the conclusions of positive economics; if there were, there would be no separate normative science. Two individuals may agree on the consequences of a particular piece of legislation. One may regard them as desirable on balance and so favor the legislation; the other, as undesirable and so oppose the legislation. (page 5)\n\nThe Case for Positive Economics\nNormative versus positive economics\nPolicy questions center around ‚Äúwhat policy should we as a society enact?‚Äù\nIn order to answer this we must be able to answer ‚Äúif we enacted this policy what will happen?‚Äù\n\nI venture the judgment, however, that currently in the Western world, and especially in the United States, differences about economic policy among disinterested citizens derive predominantly from different predictions about the economic consequences of taking action - differences that in principle can be eliminated by the progress of positive economics - rather than from fundamental differences in basic values, differences about which men can ultimately only fight.‚Äù \\(page 7\\)\n\n\nThe ultimate goal of a positive science is the development of a ‚Äútheory‚Äù or, ‚Äúhypothesis‚Äù that yields valid and meaningful i.e., (not truistic) predictions about phenomena not yet observed. Such a theory is, in general, a complex intermixture of two elements. In part, it is a ‚Äúlanguage‚Äù designed to promote ‚Äúsystematic and organized methods of reasoning.‚Äù In part, it is a body of substantive hypotheses designed to abstract essential features of complex reality. \\(page 7\\)\n\nTranslation\nPositive Economics consists of two parts:\nA completely self-enclosed formal system consisting of assumptions and implications drawn from those assumptions\nThe hypotheses stated in the language of the science that abstracts ‚Äúessential features‚Äù of the reality it purports to explain.\nPopperian perspective\nthe only relevant test of the validity of a hypothesis is comparison of its predictions with experience. The hypothesis is rejected if its predictions are contradicted ‚Äúfrequently‚Äù or more often than predictions from an alternative hypothesis; it is accepted if its predictions are not contradicted; great confidence is attached to it if it has survived many opportunities for contradiction. Factual evidence can never ‚Äúprove‚Äù a hypothesis; it can only fail to disprove it, which is what we generally mean when we say, somewhat inexactly, that the hypothesis has been ‚Äúconfirmed‚Äù by experience\nDigression I: logical positivism\nOrigin in the Vienna circle of 1920s. Cfr. H.Feigl, R.Carnap, H.Reichenbach, M.Schlick\nSix tenets or tendencies (cfr.Hacking1983: 41-42):\nEmphasis upon verification\nPro observation\nAnti-cause\nDownplaying explanation\nAnti-theoretical entities\nTo sum up: against metaphysics!\n\nPopper‚Äôs variant: falsificationism\nPopper emphasized within this tradition two things:\nmodus tollens - If P implies Q and Q is false, then P is false. (related to _red uctio ad absurdum)\nSimplicity\nDuhem-Quine problem\n\nUnfortunately, we can seldom test particular predictions in the social sciences by experiments explicitly designed to eliminate what are judged to be the most important disturbing influences. Generally, we must rely on evidence cast up by the ‚Äúexperiments‚Äù that happen to occur‚Ä¶No experiment can be completely controlled, and every experience is partly controlled, in the sense that some disturbing influences are relatively constant in the course of it. (page 10)\n\nTranslation\nThe predictions that arise from economic theory are typically ‚Äúceteris paribus‚Äù statements.\nHolding all else equal, a change in X causes a change in Y#\nUnfortunately the data never ‚Äúholds all else equal‚Äù ‚Äì it is always full of ‚Äúdisturbing influences‚Äù\nThe inability to conduct ‚Äúrandomized experiments‚Äù makes these disturbing influences especially hard for taking theory to data.\n\nThe difficulty in the social sciences of getting new evidence for this class of phenomena and of judging its conformity with the implications of the hypothesis makes it tempting to suppose that other, more readily available, evidence is equally relevant to the validity of the hypothesis-to suppose that hypotheses have not only ‚Äúimplications‚Äù but also ‚Äúassumptions‚Äù and that the conformity of these ‚Äúassumptions‚Äù to ‚Äúreality‚Äù is a test of the validity of the hypothesis different from or additional to the test by implications. This widely held view is fundamentally wrong and productive of much mischief. \\(page 14\\)\n\nThe F-twist\n Truly   important   and   significant   hypotheses   will   be   found   to   have   ‚Äúassumptions‚Äùthat   are   wildly   inaccurate   descriptive   representations   of   reality,   and,   in   general,   the   more   significant   the   theory,   the   more   unrealistic the   assumptions   in   this   sense.  The reason is simple. A hypothesis is important if it ‚Äúexplains‚Äùmuch by little, that is, if it  abstracts  the common and crucial elements from the mass of complex and detailed circumstances surrounding the phenomena to be explained and permits valid predictions on the basis of them alone. To be important, therefore, a hypothesis must be  descriptively   false  in its assumptions; it takes account of, and accounts for, none of the many other attendant circumstances, since its very success shows them to be irrelevant for the phenomena to be _explained_ (F53: 14-15, emphasis added)\nDigression II: realism vs.¬†instrumentalism\nProblem of unobservables :lack of direct sensory access to theoretical entities in science (e.g.electrons,quarks,radiowaves,viruses,demandcurve,permanentincome,velocityofmoney)\nRealism : scientific theories \\(should\\) deliver true description of the world (or of some structure of the world),including the unobservable part\nemphasis on description and explanation\n\nInstrumentalism : we are in no position to get true descriptions of the world: theories are useful instruments to generate predictions\nemphasis on prediction and manipulation\n\nRealism vs.¬†realisticness\nIn economics it is particularly important to distinguish realism ,which emphasizes the possibility of identifying faithful description of some structures of reality,from the degree of accurateness of the description.\nUskali M√§ki (1994, 1998) calls descriptive accuracy realisticness\nThus one can be realist with respect to some model or theory without emphasizing its realisticness\nThe importance of abstractions and idealizations\nF. on the realism of the assumptions\nthe relevant question to ask about the ‚Äúassumptions‚Äù of a theory is not whether they are descriptively ‚Äúrealistic,‚Äù for they never are, but whether they are sufficiently good approximations for the purpose in hand. And this question can be answered only by seeing whether the theory works, which means whether it yields sufficiently accurate _predictions. (F53:15)\nFirst example: Galilean experiment\nIt is an accepted hypothesis that the acceleration of a body dropped in a vacuum is a constant - g, or approximately 32 feet per second per second on the earth - and is independent of the shape of the body, the manner of dropping it, etc. This implies that the distance traveled by a falling body in any specified time is given by the formula s = (1/2)gt^2 , where s is the distance traveled in feet and t is time in seconds. The application of this formula to a compact ball dropped from the roof of a building is equivalent to saying that a ball so dropped behaves  as   if  it were falling in a vacuum. Testing this hypothesis by its assumptions presumably means measuring the actual air pressure and deciding whether it is close enough to zero. (F53: 16-17, emphasis added)\nThis example illustrates both the impossibility of testing a theory by its assumptions and also the ambiguity of the concept ‚Äúthe assumptions of a theory.‚Äù The formula s =(1/2) gt^2 is valid for bodies falling in a vacuum and can be derived by analyzing the behavior of such bodies. It can therefore be stated: under a wide range of circumstances, bodies that fall in the actual atmosphere behave as if they were falling in a vacuum. The formula is accepted because it works, not because we live in an approximate vacuum - whatever that means. (F53: 17-18)\nTranslation\nA Galilean Assumption: Air Pressure = 0\nRole of assumption: All forces other than gravitation = 0\nIdealizes gravity as the sole cause of the motion of a falling body, assuming all other forces are powerless.\nA Neoclassical Assumption: Producers and traders pursue maximum expected returns\nRole of assumption: All other motives except the maximization motive have zero strength.\nSecond example: an evolutionary argument\nConsider the density of leaves around a tree. I suggest the hypothesis that the leaves are positioned  as   if   each   leaf   deliberately   sought   to   maximize   the   amount   of   sunlight   it   receives  , given the position of its neighbors,  as   if   it   knew   the   physical   laws  determining the amount of sunlight that would be received in various positions and could move rapidly or instantaneously from any one position to any other desired and unoccupied position. Now some of the more obvious implications of this hypothesis are clearly consistent with experience: for example, leaves are in general denser on the south than on the north side of trees but, as the hypothesis implies, less so or not at all on the northern slope of a hill or when the south side of the trees is shaded in some other way. ... the hypothesis does not assert that leaves do these things but only that their density is the same  as   if  they did. Despite the apparent falsity of the ‚Äúassumptions‚Äù of the hypothesis, it has great plausibility because of the conformity of its implications with observation. (F53: 19-20, emphasis added)\nThird example: the billiard player\nConsider the problem of predicting the shots made by an expert billiard player. It seems not at all unreasonable that excellent predictions would be yielded by the hypothesis that the billiard player made his shots  as   if  he knew the complicated mathematical formulas that would give the optimum directions of travel, could estimate accurately by eye the angles, etc., describing the location of the balls, could make lightning calculations from the formulas, and could then make the balls travel in the direction indicated by the formulas. (F53:21)\n\nNow, of course, businessmen do not actually and literally solve the system of simultaneous equations in terms of which the mathematical economist finds it convenient to express this hypothesis, any more than leaves or billiard players explicitly go through complicated mathematical calculations‚Ä¶ The billiard player, if asked how he decides where to hit the ball, may say that he ‚Äújust figures it out‚Äù but then also rubs a rabbit‚Äôs foot just to make sure; and the businessman may well say that he prices at average cost, with of course some minor deviations when the market makes it necessary. The one statement is about as helpful as the other, and neither is a relevant test of the associated hypothesis.\n\nBottom line\nindividual firm behave as if they were seeking rationally to maximize their expected returns ...and had full knowledge of the data needed to succeed in this attempt; as if, that is, they knew the relevant cost and demand functions, calculated marginal cost and marginal revenue from all actions open to them, and pushed each line of action to the point at which the relevant marginal cost and marginal revenue were equal. (F53:21)\nF.‚Äôs ambiguities\nIt would not be fair to dub F. as an instrumentalist\nHe swings between realism (but anti-realisticness) and instrumentalism\nEspecially if we judge F53 vis-√†-vis Friedman and Schwartz (1963) and his professed Marshallian methodology\nMarshall took the world as it is; he sought to construct an ‚Äúengine‚Äù to analyze it, not a photographic reproduction of it (F53:35)\nConclusion\nThe relevant hypothesis is: ‚ÄúI can treat the data of interest AS IF it were generated by the ideal types contained in my model‚Äù.\nA reasonable starting point if model was generated by isolating essential features of reality in the first place.\nHow can we test our model of Homo Economicus\nImagine the following question was asked to a decision maker:\nYou won a free ticket to an Eric Clapton concert.\nBob Dylan is playing on the same night and is your most attractive alternative.\nTicket to see Dylan is $40\nYou would be willing to pay up to $50 to see Dylan\nNo other costs of seeing either performer\nWilling to pay $50 to see Dylan\nCost of Dylan ticket = $40\nBased on this information, what is the opportunity cost of seeing Clapton?\n$0\n$10\n$40\n$50\n7.4% of 270 undergrads who had previously taken a course in economics answered the question correctly\n17.2% of 88 undergrads who had never taken a course in economics answered the question correctly\nWhat would Friedman say to this data as a test against Homo Economicus\n\n\n\n",
    "preview": "http://c250.columbia.edu/images/c250_celebrates/remarkable_columbians/240x240_bio_friedman.jpg",
    "last_modified": "2021-02-02T13:25:15+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-28-visualizations/",
    "title": "Some Famous Data Visualizations",
    "description": "A look at some visualizations from the pre-digital era",
    "author": [
      {
        "name": "Amit Gandhi",
        "url": {}
      }
    ],
    "date": "2021-01-28",
    "categories": [],
    "contents": "\nNapolean‚Äôs March\nDesigner: Charles Joseph Minard\n\nThe Cholera Map\nDesigner: John Snow\n\nWorld War II Fighter Planes\nDesigner: Abraham Wald\n\n\n\n\n",
    "preview": "https://cdn8.openculture.com/2019/07/11094725/Minard-1-e1562863679105.png",
    "last_modified": "2021-01-28T17:47:19+00:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "An Introduction to Homo Economicus",
    "description": "Who is Homo Economicus and how is he/she related to you?",
    "author": [
      {
        "name": "Amit Gandhi",
        "url": "upenn.edu"
      }
    ],
    "date": "2021-01-28",
    "categories": [
      "Data",
      "Cloud",
      "Homo Ecnoomicus",
      "Behavioral Economics"
    ],
    "contents": "\n\nContents\nIntroduction\n(Re-)Introducing Homo Economicus\nHow did Homo Economicus evolve?\nLets try an Example\n\n\nKey Assumptions\nWhat are the traits of Homo Economicus\nBut You are Actually Homo Sapien\n\nWhat should be done?\nA question\n\nIntroduction\n\n\n\n\nLife is a matter of choices, and every choice you make makes you.\n‚ÄîJohn C. Maxwell\n\nEconomics is the science of choices - choice under scarcity specifically. Of course given that all choices involve an opportunity cost - the value of your next best alternative to the choice that was actually made - all choices are made in the presence of scarcity. Or said another way, in the words of a famous economic theorem you have likely heard - there is no free lunch!1\nThe way economics approaches this science is actually a little quixotic and takes some time to appreciate the angle of attack. In order to understand the choices made by actual people in an economic system, an economic model will typically start with asking what may seem like an unusual question: what would a hypothetical rational actor choose under the circumstances faced by actual person or entity making the choice?\nNotice that this is distinct from asking : ‚Äúwhat would the actual person or entity in question choose?‚Äù. The reason for the difference is that the ‚Äúrational actor experiment‚Äù - embedding a hypothetical rational actor in the setting faced by an actual decision maker - provides insight into the major forces that determine the outcome of the decision. By mapping the cause and effect relationship from decision forces to behavior, it enables economists to predict what different decisions could result as those forces are altered.\nA key force of interest in economics are incentives. Hence the rational actor is not meant to be a perfect replication of the entity in question in question making the decision, but rather a model that provides an approximation and is designed to isolate the effect of incentives on behavior.\nThis actor interestingly enough has a name: Homo Economicus. It is a whole species of humanity that abides by the axioms of rational choice!\n\nHomo Economicus\n(Re-)Introducing Homo Economicus\nIf you don‚Äôt remember your Homo Economicus, lets have a quick refresher. Consider the list of options below which represent potential payoffs from choosing that option. Which option would you choose.\n\n\n\nThe answer should likely jump off the page. The option 20 feels (and indeed is) the highest payoff, and given that all else equal you prefer more to less, you choose it.\nIf you have chosen in this fashion, there is a Homo Economicus living inside of you. You have entered a choice situation with a clear objective - maximize payoff. Yo also likely delibratively considered each option and assessed the one which best fulfilled your objective. In other word, you have just maximized the utility subject to a budget constraint - a key capability of Homo Economicus!\nHow did Homo Economicus evolve?\nHomo Economicus was historically discovered not through laboratory experiments, but rather through a process of human introspection. A collection of scholars spanning multiple fields - ranging from Economics, Mathematics, Statistics, Computer Science, Operations Research, as well as Psychology and Sociology and even Philosophy - have all contributed to the modern conception of Homo Economicus by asking a common question: How should a rational actor behave given the logical structure of a decision problem.\nThis introspective methodology created the basic DNA of Homo Economicus. This DNA has evolved from the 18th century enlightenment thought to the present day in a fashion akin to natural selection as a wider variety of decision problems confronted Homo Economicus. These problems arose from a practical need to solve economic questions as opposed to completely abstract undertakings - e.g., they were problems truly found in the wild of applied economics.\nHomo Economicus is thus a human creation - a model built by humans for humans to shed light and understanding on the human condition.\nHomo Economicus HistoryLets try an Example\nDecision Maker Doris who lives for two periods\nIn each period she will receive some income.\nIn the first period does not know what income in second period will be\n\nIn each period will spend money on two goods\nBourbon \\(b\\) or Yoga classes \\(y\\)\nShe has utility \\(u(b,y)\\) from consuming these two goods in any period she consumes them\n\nCan borrow and save between periods at interest rate \\(r\\), but cannot die in debt\nOur job (as economists) is to predict how Doris is going to behave -How much bourbon and yoga she will she consume in each period? -How much will she save?\nHow would Homo Economicus solve this decision problem?\nKey Assumptions\nDoris makes optimal choices ‚Äì i.e. maximizes her utility\nDoris‚Äôs tastes do not change between period 1 and 2\nDoris forms the correct expectations about income in period 2, and makes choices based on expected utility\nThe only thing that appears in Doris‚Äôs utility function is the amount of bourbon and yoga consumed -No ‚Äòreference points‚Äô -Not other people‚Äôs consumption\nDoris makes optimal choices ‚Äì i.e. maximizes her utility\nDoris‚Äôs tastes do not change between period 1 and 2\nDoris forms the correct expectations about income in period 2, and makes choices based on expected utility The only thing that appears in Doris‚Äôs utility function is the amount of bourbon and yoga consumed -No ‚Äòreference points‚Äô -Not other people‚Äôs consumption\nWhat are the traits of Homo Economicus\nThe core anatomy of Homo Economicus that has emerged in modern economics encompasses the following set of traits:\nHas stable preferences\nMaximizes utility\nForms beliefs about uncertain outcomes satisfying laws of probability distributions (probablistic sophistication)\nUpdates beliefs with new information through Bayes Rule\nMakes decisions under uncertainty according to the principle of expected utility\nMakes decision over time in accordance with Bellman‚Äôs principle (dynamically consistent).\nThese traits are able to mix and match together depending on the structure of the choice problem to give rise to a very general model of rational behavior that is highly adaptable to most decisions. One of the first skills taught to graduate students in economics is to build a Homo Economicus in problem sets and computer simulations and to observe its behavior!\nBut You are Actually Homo Sapien\nAll of this is great for the economics profession by what does it matter to you. Consider the following variation of the choice problem we presented above. What choice would you make among the following options.\n\n\n\nThis choice problem feels different and triggers a rather different thought process. It is harder and your conclusion is more uncertain although there is no uncertainty in the question. Likely you will start to do a few operations of addition which you full well understand how to do in theory but don‚Äôt particularly enjoy in practice. You will grow slightly weary of this repetition (different individuals will have a different threshold for this pain), you will then resort to glancing through the patterns of the numbers in the numbers and ‚Äúrecognize‚Äù through an intuitive sense which is the highest payoff from among these based on this pattern.\nIf you functioned in this way, then congratulations you are indeed human - i.e., Homo Sapien! Homo Sapien, unlike Homo Economicus, is governed by another ‚Äúthinking and reasoning system‚Äù that allows you to quickly assemble data from the environment, make sense of it, draw conclusions, and make decisions in a fairly automatic fashion. This thinking system stands at the front line of many decisions you actually make. It is distinguished by its remarkable speed and fairly effortless operation.\nFor Homo Economicus the two presentations of the decision problem yield the exact same choice - the the problems are logically identical becauset the choice options themselves are mathematically equivalent. However for Homo Economicus they lead us down different ‚Äúthinking‚Äù pathway. The end result of the two pathways lead to materially different decisions.\nConsider the following data from an experiment conducted in 2011 by Caplin, Dean, and Martin (see here), they presented 22 Subjects with 657 choices analgous to the choices above but the choice problem varied among subjects in two key dimensions:\n2 complexity levels: 3 or 7 operations\n3 choice set sizes: 10, 20, 40 options\nwhich gave 6 overall treatments. An example of a choice problem can be seen below: \nThe results of the study are found below:\n\n\n\nThe outcome reveals a few key realities that will be central themes for us:\n1) Homo Sapien falls short of the rational ideal of Homo Economicus - Homo Sapien is boundedly rationality. \n2) The more complex environment exacerbates the difference with considerable heterogeneity among individuals. \n3) Homo Sapien‚Äôs choices are however reasonably effective - we leave cash on the table, but the level of inefficiency experienced is perhaps acceptable given the onerous calculations that would have been involved.\nWhat should be done?\nHere is where our chief quandary will lie.\nEconomists for the most part build fairly sophisticated models of Homo Economicus through data, theory, and econometric technique which are motivated by real world problems faced by actual economic actors.\nBut at the end of the day you on the other hand are Homo Sapien. We are left with two options to then consider:\nOption A: ¬† Economists should really be performing genetic engineering on Homo Economicus to look and act more like Homo Sapiens. In this way build more realistic models of human behavior.\nOption B: ¬† Homo Sapien should act more like Homo Economicus if indeed the latter is rational and no one is likely to dispute a basic desire to be rational.\nBoth options are interesting and quite important - there is an opportunity to build more predictive/realistic economic models and at the same time guide Homo Sapien towards a state of heightened rationality in actual behavior.\nYet neither option if tenable if the difference between Homo Sapien and Homo Economicus and Homo Sapien is due to the whims and randomness of passion. That is, if the dividing line between Homo Economicus and Homo Sapien is attributable to a third specimen of being - Homo Emotionalis.\n\n\n\nThis point of view was the established wisdom in the social sciences for the better part of the 20th century. The relevant departures from rational choice where the outcome of emotional reactions to the environment - the behavior of Homo Emotionalis.\nUnder this paradigm, the general predisposition towards Homo Economicus was the norm, with the countervailing influence of an emotions that leading to momentary but significant departures from the rational norm.\nMathematically we can imagine a theory of behavior under this view of people that resembled:\n\\[\n\\color{blue}{\\mbox{actual behavior} = \\mbox{rational behavior} + \\epsilon}\n\\]\nwhere \\(\\epsilon\\) is a random factor that causes our real behavior to fluctuate from the tenants of rational choice.\nUnder this model, our rational selves are at the center and the emotional perturbations are disruptions to the center. This model\nThis rational system of thought which you are capable of internalizing we will identify with a dimension of your brain following Kahneman as your ‚ÄúSystem 2‚Äù. The other designations we can give System 2 are your deliberate, rational, and formal thought system.\nThe view emerging from System 1 and System 2 is actually \\[\n\\color{blue}{\\mbox{actual behavior} = \\mbox{intuitive behavior} + \\mbox{rational adjustmnet}}\n\\]\nSystem 2 is your inner Homo Economicus. It can follow the precepts of formal reasoning and motivate action on that basis. It is however lazy. It takes cues from system 1. All else equal it would rather outsource its job to another complementary This intuitive system of thought we will represent as another dimension of your brain that (following Kahneman) will call ‚ÄúSystem 1‚Äù.\nNow we recognize that System 1 and System 2 are both present at the moment we are making a decision. Our main text in the class - thinking fast and slow - will be focused on the dual operation of System 1 and System 2 and how they operate together in a rich interplay that guides human decisions to predictably depart from Homo Economicus.\nA question\nWhy don‚Äôt we just take classes in decision making to solve the problem?\n\nThe choices are made by a set of economic actors whose decisions interrelate to give rise to the fundamental economic outcomes in society. This includes what gets produced, how is it produced, and who receives it. The underlying actors themselves encompass consumers/households, firms/organizations, governments, and the market mechanism itself - e.g., the invisible hand.‚Ü©Ô∏é\n",
    "preview": "https://theprogenygroup.com/wp-content/uploads/2016/06/homo-economicus.jpg",
    "last_modified": "2021-01-28T17:33:19+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-26-perusall-information/",
    "title": "Perusall Information",
    "description": "A short description of how Perusall works",
    "author": [
      {
        "name": "Amit K. Gandhi",
        "url": "upenn.edu"
      }
    ],
    "date": "2021-01-26",
    "categories": [],
    "contents": "\n\nHow Perusall Works\nPerusall helps you master readings faster, understand the material better, and get more out of your classes. To achieve this goal, you will be collaboratively annotating the textbook with others in your class.\nThe help you‚Äôll get and provide your classmates (even if you don‚Äôt know anyone personally) will get you past confusions quickly and will make the process more fun. While you read, you‚Äôll receive rapid answers to your questions, help others resolve their questions (which also helps you learn), and advise the instructor how to make class time most productive.\nYou can start a new annotation thread in Perusall by highlighting text, asking a question, or posting a comment; you can also add a reply or comment to an existing thread. Each thread is like a chat with one or more members of your class, and it happens in real time. Your goals in annotating each reading assignment are to stimulate discussion by posting good questions or comments and to help others by answering their questions.\n\n\n\n\n\n\n\n\n\n\n\nResearch shows that by annotating thoughtfully, you‚Äôll learn more, so here‚Äôs what ‚Äúannotating thoughtfully‚Äù means: Effective annotations deeply engage points in the readings, stimulate discussion, offer informative questions or comments, and help others by addressing their questions or confusions. To help you connect with classmates, you can ‚Äúmention‚Äù a classmate in a comment or question to have them notified by email (they‚Äôll also see a notification immediately if online), and you‚Äôll also be notified when your classmates respond to your questions.\nFor each assignment, the application will evaluate the annotations you submit on time (see below). Based on the overall body of your annotations, you will receive a score for each assignment as follows\n\n3 = demonstrates exceptionally thoughtful and thorough reading of the entire assignment\n2 = demonstrates thoughtful and thorough reading of the entire assignment\n1 = demonstrates superficial reading of the entire assignment OR thoughtful reading of only part of the assignment\n0 = demonstrates superficial reading of only part of the assignment\n\nHow many annotations do I need to enter?\nWhen Perusall examines your annotations, its ‚Äúassessment engine‚Äù has been designed to reflect the effort you put in your study of the text. It is unlikely that that effort will be reflected by just a few thoughtful annotations per assignment. On the other extreme, 30 per assignment is probably too many, unless a number of them are superficial or short comments or questions (which is fine, because it is OK to engage in chat with your peers). Somewhere in between these two extremes is about right and, thoughtful questions or comments that stimulate discussion or thoughtful and helpful answers to other students‚Äô questions will earn you a higher score for the assignment.\nWhat does ‚Äúon time‚Äù mean?\nThe work done in class depends on you having done the reading in advance. We will use the data arising from student responses on Perusall reading assignments as a guide for classroom discussion. Hence it is necessary to complete the reading and post your annotations before the deadline to receive credit. The deadline is a hard deadline, typically set 11pm on the night prior to the day of the lecture the reading is discussed.\n\n\n\n",
    "preview": "https://lms.unimelb.edu.au/__data/assets/image/0004/3355654/tile-perusall.png",
    "last_modified": "2021-01-26T15:09:59+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-25-course-introduction/",
    "title": "Course Introduction",
    "description": "Economics at the Intersection of Data and Technology",
    "author": [
      {
        "name": "Amit K. Gandhi",
        "url": "upenn.edu"
      }
    ],
    "date": "2021-01-25",
    "categories": [
      "Data",
      "A.I.",
      "Homo Economicus",
      "Behavioral Economics"
    ],
    "contents": "\n\nContents\nWelcome\nWhat is Market Design?\nWhat is the Topic of Our Class?Our approach to market design\nHow does this differ from data science?\n\nHow We Will LearnReading (50%)\nProject (50%)\n\nCourse Logistics\nCourse ScheduleWeek 01, 01/18 - 01/22\nWeek 02, 01/25 - 01/29\nWeek 03, 02/01 - 02/05\nWeek 04, 02/08 - 02/12\nWeek 05, 02/15 - 02/19\nWeek 06, 02/22 - 02/26\nWeek 07, 03/01 - 03/05\nWeek 08, 03/08 - 03/12\nWeek 09, 03/15 - 03/19\nWeek 10, 03/22 - 03/26\nWeek 11, 03/29 - 04/02\nWeek 12, 04/05 - 04/09\nWeek 13, 04/12 - 04/16\nWeek 14, 04/19 - 04/23\nWeek 15, 04/26 - 04/30\nWeek 16, 05/03 - 05/07\n\n\n\n\n\n¬†\n¬†\n Course \nEcon 262\n Professor\nAmit Gandhi (akgandhi@upenn.edu)\n TA\nNawaaz Khalfan (khalfan@sas.upenn.edu)\n Lecture \nTues, Thursday 1.30-2.50\n Office Hours \nBy appointment\n Website \nmarketdesign.io\n\n\nWelcome\nWelcome to Market Design (Econ 262)! This is a virtual course in the economics of decision making being taught in the Spring of 2021 at the University of Pennsylvania. This page describes the topic of the course, the learning objectives, the logistical plan, the evaluation policies, and the class schedule.\nThe course website will act as a central repository for the class to disseminate lecture materials and announcements. A GroupMe group for the class has been setup (reach out to Amit for access if you do not have it yet) and will serve as our platform to communicate with each other, conduct flash polls, and send reminders of class activities (including links for zoom class meetings.)\nWhat is Market Design?\nThe goal of market design is to design policies that improve the efficiency of economic decisions. An economic decision is any decision that involves trade-offs, which is synonymous with the very definition of economics as ‚Äúthe study of the allocation of scarce means to satisfy competing ends.‚Äù (Becker 2017)\nEconomic decisions are made by diverse actors in an economic system - households, firms, governments, and even the markets themselves (e.g., the invisible hand!).\nAn economic decision is efficient if it makes an optimal trade-off given the objectives and constraints of the decision maker.\nHelping make decisions more efficient creates value, generates profits, and raises welfare. But how should such interventions be designed? This is the central problem of market design.\nWhat is the Topic of Our Class?\nOur class is focused on the problems of market design in digital environments.\nHumans are increasingly making decisions in the presence of screens and devices, both at work and home. This has been especially pronounced during the last year of the pandemic where life quite literally moved online!\n\nA digital environment is one where computers and devices are networked together to facilitate human communication and transactions.\nWhat is the impact of digital environments on economic decisions? Does the transition from offline to digital environment improve economic efficiency? Can digital environments be designed to enable humans to better optimize their economic decisions?\nThese are central questions for market design in digital environments.\nA key difference between digital decisions and their offline counterparts is the role of data. A digital decision can leverage unprecedented velocity, variety, and volume  of data. The proliferation of data is a product of technological advancements in data science, data engineering, data analytics, machine learning, and A.I, which are distributed to decision makers through public cloud infrastructure.\nA fundamental question is then:\n\nMore Data = Better Decisions?\n\nThe answer is not as straightforward as it may seem. From a purely statistical or econometric viewpoint - more data is always better - we get better parameter inferences, better predictive accuracy, and better power to test models.\nHowever from a decision making perspective matters are less clear. The main problem is that data and A.I. - despite the hype - is not a panacea by itself. The technologies alone do not magically transform decisions. As economists are fond of saying, there is no free lunch!\nHal Varian (Chief Economist at Google and Professor at Berkeley) summarized the matter nicely in a recent interview:\n\nI think there‚Äôs a mystical belief in the power of data. Data is like oil in one respect‚Ä¶ namely, it needs to be refined in order to be useful. So the data itself is not the important components, the know-how to refine it into something that‚Äôs useful. It‚Äôs the same [when] we talk about oil or data ‚Äì it‚Äôs just the raw material, it‚Äôs not the finished product.\n\nIn order to create value, data technologies need to be transformed into applications that solve real problems and improve economic decisions. That is, applications need to be designed to extract value from data. Without good design, we are left with an alternative possibility:\n\nMore Data =  More Complexity =  Worse Decisions!\n\nA  central problem  for market design is  designing digital environment to translate ‚Äúmore data‚Äù into ‚Äúbetter economic decisions‚Äù..\nOur approach to market design\nHow should digital environment be designed to enable efficient economic decisions?\nThe first rule of good design is to know your audience. For whom are we designing? Who is the user?\nLet me state the obvious answer which nevertheless has some profound implications for market design. The user is a human being!\n\nYou cannot understand good design if you do not understand people; design is made for people.\n\n‚Äî Dieter Rams\n\nOur approach in the class is to start with the user - the human - and understand how humans process and act upon data for economic decision making.\nHumans interact with raw data in a digital environment typically through a web application. The application processes, models, summarizes, and displays features of the raw data to the user, who internalizes the information in their behavior.\n\nThus from a user perspective, effective design in digital environments requires that a market designer to do 3 things:\n1. Identify an existing inefficiency in a human decision making process.\n2. Improve the the decision by leveraging data, technology, and economics.\n3. Influence humans to change their behavior toward the efficient outcome through digital interfaces.\n\nThe design problem encompasses all three steps. We can see that success in a market design project involves holistic thinking that integrates data/economic techniques with the visual elements of the digital interface, which are all tailored to the human behaviors we aim to effectuate and improve.\nThis is hard! It is a domain that is still in its infancy and being developed in real time across academic, business, and government as organizations digitally transform make data more central to their operation.\n\nHow does this differ from data science?\nA standard data science or machine learning classes will focus attention on the elements (2) (usually substituting ‚Äúbetter decisions‚Äù with ‚Äúbetter predictions‚Äù). These classes will focus on software techniques and algorithms for building and deploying ML algorithms.\nWe are instead interested in the underlying human decision problems that these algorithms and ultimately the data are intended to improve. Thus our focus is defining the problem (1) and generating influence (3), which provides the perspective necessary for solving (2).\nThus our focus is the human-centered design of data technologies to enhance economic decisions.\n\nI recognize that combining ‚Äúhuman-centered‚Äù and ‚Äúeconomic‚Äù together is not often how the ‚Äúdismal science‚Äù is practiced or perceived. üòÑ\nHow We Will Learn\nIn order to solve the design problem above, we need to understand our user - human decision makers - in the wild. The investigation will proceed along two parallel tracks of learning in the class:\nReading\nCourse Project\nEach will count 50% towards your final course evaluation.\nThere is no curve in this class and hence no quotas on A‚Äôs or C‚Äôs. If you earnestly attempt to think and understand down each of these tracks, the metrics we have set up (and described below) will detect it and you will do well.\nReading (50%)\nA core learning experience in the course is rooted in reading the assigned book chapters and papers, and discussing them as a class. We will add a technological twist to this age old formula by adopting the  Perusall  application.\nOur Perusall code for the class is GANDHI-HUX9J. Go to to the Perusall website and enter this code to access our class library where all reading assignments will be posted.\nPerusall manages your engagement in the weekly readings. Perusall itself is based on an intelligent data technology that is aiding a key form of decision making in the classroom - student evaluations! Perusall measures engagement by your annotations in the reading, which forces you into an active reading mode through similar social forces that motivate our online media habits - it thus also embodies key features of Nudge (one of the books below)!\nOur readings fall into two categories:\nReading to gain perspective on human biases in decision making relative to efficient economic norms, and the effect of data on the manifestation of those biases.\nReading to learn tools for understanding human users and influencing them with the data scientific artifacts.\nWe describe the main texts that are part of the reading:\nThinking Fast and Slow\n\nIn order to identify and influence economic inefficiencies in the wild, we need a map to know where to look. If human departures from efficient decisions happen completely at random, then the search would be difficult if not impossible - we would be at the mercy of luck to successfully design!\nFortunately this is not the case. What is arguably the biggest discovery in the social and behavioral science in the last 50 years is that there are robust patterns of human cognition that make humans, e.g, Homo Sapien behave differently than the rational ideal, e.g., Homo Economicus.\nThe science we will apply to the question follows from the seminal work of Kahneman and Tversy (KT for short) who in 1971 began the first inquiry into the question of whether humans naturally are intuitive statisticians - e.g., do humans instinctively process data in a fashion that abides by formal statistical principles?\n\nThe surprising answer to the question was ‚Äúno‚Äù, and led to an influential research paradigm known as ‚ÄúHeuristics and Biases‚Äù (H&B for short).\nThe crux of H&B, which is among the biggest discovery in the social and behavioral sciences of the last 50 years, is that there are robust patterns of human cognition that make humans, e.g, Homo Sapien behave differently than the rational ideal, e.g., Homo Economicus. The program spawned the field of behavioral economics and led to Kahneman being awarded the Nobel Prize for Economic Science in 2002 (Tversy sadly passed away in 1996).\nHomo Economicus is the \"rational actor&quot from your principles of economics courses used to model decisions by consumers, firms, and societies/governments.\nThe book ‚ÄúThinking Fast and Slow‚Äù by Daniel Kahneman - describes the conceptual and historical backdrop behind H&B and provides the basic clues for where we can anticipate that sub-rational economic decisions will happen. Identifying these scenarios is a central part of being a market designer in the digital age - data and AI when properly employed should ameliorate these biases and improve economic efficiency.\nNudge (optional)\n\nIdentifying an inefficiency in an economic decision is one thing. Changing someone‚Äôs behavior towards a more efficient state is quite another. No one likes to be told what to do, especially from data they may not fully be aware or understand.\nPerhaps the answer lies not in directing the outcome of the decision, but rather to nudge the decision maker towards the rational outcome while respecting their autonomy over the decision.\nThis is the key idea behind the book Nudge by Richard Thaler and Cass Sunstein. Richard Thaler is a behavioral economist who developed the first economic applications of Kahneman and Tversky‚Äôs discoveries. He was awarded the Nobel prize himself in 2017.\nAn implication of H&B for market design is that it is not simply what data is presented to humans, but how they are presented that affects which economic decisions are made. It implies that both the presentation of information as well as the information itself are part of the design problem. Said another way - The interface matters!\nNudge applies this fact and recognizes that interfaces (what they call choice contexts) can manipulated and hence designed to produce decisions that are more rational. Thaler and Sunstein call this type of market design choice architecture - designing the choice environment to nudge people to behave more rationally without having to make people ‚Äúthink‚Äù more rationally!\nHowever the practice of designing nudges has a potential dark side - especially in digital environments. They can be used to exploit human frailties to extract profits in a way that may not be human welfare improving to the user. Of course the definition of welfare itself can be in the eye of the beholder, and the dividing line between good vs evil nudges is not always clear. We will aim to be mindful of this important complexity as we explore the topic.\nR for Data Science\n\nBoth ‚ÄúThinking Fast and Slow‚Äù and ‚ÄúNudge‚Äù were written before data science came of age. In fact the term ‚Äúdata science‚Äù itself was coined in 2008 (by D.J. Patil and Jeff Hammerbacher), the same year as Nudge was published.\n\nData science is in many ways represents the modern day choice architecture. Data scientist in organizations across industries are processing, filtering, and designing displays of information that defines the context for a large variety of our economic decisions.\nData science should be seen as both a set of tools for working with data, as well as a process for answering questions and solving problems with data to influence stakeholders seeking value from data (typically decision makers who are the clients or customers of a data analysis). The book R for Data Science written by Hadley Wickham has become a ``modern classic‚Äô‚Äô in establishing an elegant and powerful set of tools and processes.\nThe tools he describes, including ggplot, dplyr, and tibbles, are the staples of being a productive data scientist. The process, which sometimes receives less attention, is just as powerful and encapsulated by the following data science workflow: \nThe tidyverse is a collection of packages that have a common set of design principles and interfaces that juxtaposes against this workflow to create a rich ecosystem for data science. A sampling of the most popular packages can be seen here: \nParticularly of interest for digital design of decisions is the communication step. As can be seen, communication is the last mile of the data scientific workflow and it is arguably the most important (and unfortunately least taught!). The communicaton step is associated to a specific tooling element: rmarkdown.\nRmarkdown weaves together code, text, and visualizations in a single software medium intended for human consumption. It lives as a text file, e.g., a piece of code, which can be versioned and generates a communication that is reproducible. We will examine rmarkdown and the process of building data based communications that can influence the behavior of human decision makers.\nProject (50%)\nYou will work in teams of 3-4 and engage in a human centered design process that applies data to help solve a decision problem. The process will entail 7 distinct stages that you will carry your project forward with your team. The stages correspond to the elements of a human centered design process for data solutions:\n\nProject Flow\n\n\n\n{\"x\":{\"diagram\":\"digraph{\\n\\n                     graph[rankdir = TD]\\n                     \\n                     node[shape = rectangle, style = filled, fontsize = 44]  \\n                     A[label = \\\"Decision Problem\\\"]\\n                     B[label = \\\"User Persona\\\"]\\n                     C[label = \\\"User Interview\\\"]\\n                     D[label = \\\"Data Collection\\\"]\\n                     E[label = \\\"Construct Prototype\\\"]\\n                     F[label = \\\"Collect Feedback\\\"]\\n                     G[label = \\\"Iterate and Finalize\\\"]\\n\\n                     edge[color = black, fontsize = 44]\\n                     A -> B\\n                     B -> C\\n                     C -> D\\n                     D -> E\\n                     E -> F\\n                     F -> G\\n                     \\n                     }\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nThe components are:\n1: Define a decision problem of interest/concern 2: Hypothesize user personas and recruit users for interviews 3: Conduct user interviews and test/iterate the problem and persona definitions 4: Collect data for the problem 5: Construct a prototype 6: Collect user feedback on the prototype 7: Iterate and finalize prototype \nYour journey along this path will documented in a team blog. Each stage is a milestone in the project. Your output from each stage will correspond to a blog post. We will use rmarkdown for creating team blogs. Instructions for building your blog with Rmarkdown will be provided in the class.\nThe goal of the project is to get you to experience first hand what I view as the most challenging aspect of the design problem. This is usually not the technical AI, ML, or Data Science component, but rather understanding the user experience and user value for the decision being improved. The particular data technique that factors into building a prototype can be very simple - a well designed data visualization for example can more than suffice for a successful prototype, but it is the discretion of the team to find the appropriate data design for the problem at hand.\nYou are not being evaluated on the intricacy of the prototype- there is no failure! Your evaluation is based on attempting to follow the process to develop a useful scenario for the application of data to the decision problem you have scoped. A big part of success is thus having a well defined problem, which itself will feel ambiguous and will morph as you go along the process.\nThus you should see the process as an education in itself in real world design of data solution. You will struggle with ambiguity and test ideas, and discard many false starts before you find a path towards a solution that adds value to a decision problem. This is the nature of the iterative method and keeps you constantly connected to the user scenario before investing heavily in the technology side of what you are developing.\nCourse Logistics\nThe course will work in the following way.\nYou will have readings mostly due Tuesday of each week.\nWith some occasional exceptions for shorter readings that are due both Tues and Thurs, which will take place early in the semester to establish a few foundations (see schedule below).\nDuring the synchronous session on Tuesday, I will review the key highlights from your weekly reading and the Perusall questions/comments.\nThe rest of the class time on Tuesday and Thursday will be spent with me working individually with each team, and assisting with the project milestone for the week.\nI will break everyone into their team rooms where you can work together on the project milestone. I will have planned times to meet with each team during their breakout room session. Teams should be prepared with specific ideas/questions they would like to review where advice is needed to achieve the goals of the milestone\nWe will arrange a schedule for meeting in advance of the week. Each team will have a session alloted with me, and a session with Nawaaz. There is no necessity to meet with us (you can opt out), and it is intended as an aid to help unblock any challenges you may face along the process of building a data solution.\nOn select lecture dates we will have guest speakers\nThe topic we are studying is at the bleeding edge of applied practice in the data industry. As such it is useful to hear perspective on human centered design from leaders in industry. As their participation is confirmed it will be updated on the course schedule.\nCourse Schedule\nThe following schedule provides dates for readings. Most but not all readings will be assigned to Perusall. It has also marked the weeks where a project milestone begins and ends. The schedule will fill out with more detail as the semester progresses.\nWeek 01, 01/18 - 01/22\nThurs Jan 21\nTopic: Rstudio Global Conference\nRegister and attend any session(s) of the Rstudio global conference \nWeek 02, 01/25 - 01/29\nTues Jan 26\nTopic: Syllabus Day\nThurs Jan 28\nTopic: Introduction to Data Based Decisions\nüìñ tfs (Introduction)  nudge (Chapter 1)\n\nüìú Bounthavong, M. (2019). Communicating data effectively with data visualizations: Part 21. URL: https://mbounthavong.com/blog/2019/12/13/communicating-data-effectively-with-data-visualizations-part-21-examples-of-famous-and-infamous-data-visualizations-1.\nSchneider, C., M. Weinmann, and J. Vom Brocke (2018). ‚ÄúDigital nudging: guiding online user choices through interface design‚Äù. In: Communications of the ACM 61.7, pp.¬†67-73. URL: https://cacm.acm.org/magazines/2018/7/229029-digital-nudging/fulltext#R25.\n\nWeek 03, 02/01 - 02/05\nProject: Start Problem Definition\nTues Feb 2\nTopic: Homo Economicus\n\nüìú Friedman, M. (1953). ‚ÄúThe methodology of positive economics‚Äù. In: Essays in positive economics 3.3, pp.¬†145-178.\n\nThurs Feb 4\nTopic: R Markdown\n\nüìú Hohman, F., M. Conlen, J. Heer, et al.¬†(2020). ‚ÄúCommunicating with Interactive Articles‚Äù. In: Distill. https://distill.pub/2020/communicating-with-interactive-articles. DOI: 10.23915/distill.00028.\nWickham, H. (2017). ‚ÄúR Markdown‚Äù. In: R for Data Science. O‚ÄôReilly. Chap. 27.\n\nWeek 04, 02/08 - 02/12\nProject: Continue Problem Definition\nThursday Feb 11\nNo Class\nWeek 05, 02/15 - 02/19\nProject: Start User Persona\nWeek 06, 02/22 - 02/26\nProject: Continue User Persona\nWeek 07, 03/01 - 03/05\nProject: Start User Interviews\nWeek 08, 03/08 - 03/12\nProject: Continue User Interviews\nWeek 09, 03/15 - 03/19\nProject: Start Data Collection\nWeek 10, 03/22 - 03/26\nProject: Continue Data Collection\nWeek 11, 03/29 - 04/02\nProject: Build Prototype\nTues March 30\nNo class\nWeek 12, 04/05 - 04/09\nProject: Continue Build Prototype\nWeek 13, 04/12 - 04/16\nProject: Collect User Feedback\nWeek 14, 04/19 - 04/23\nProject: Continue Collect User Feedback\nWeek 15, 04/26 - 04/30\nProject: Iterate and Finalize\nWeek 16, 05/03 - 05/07\nProject: Continue Iterate and Finalize\n\n\n\nBecker, Gary S. 2017. Economic Theory. Routledge.\n\n\n\n\n",
    "preview": "https://db0ip7zd23b50.cloudfront.net/dims4/default/0dfba66/2147483647/legacy_thumbnail/960x369%3E/quality/90/?url=http%3A%2F%2Fbloomberg-bna-brightspot.s3.amazonaws.com%2F43%2F5e%2F9afb1c354b0e8ee71a13c737d4f5%2Fgettyimages-921135480.jpg",
    "last_modified": "2021-01-26T15:09:45+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-17-classsurvey/",
    "title": "First Day of Class",
    "description": "Rstudio Global Conference",
    "author": [
      {
        "name": "Amit K. Gandhi",
        "url": "upenn.edu"
      }
    ],
    "date": "2021-01-17",
    "categories": [],
    "contents": "\nThe Rstudio Global Conference\n\n\n\nAs I emailed you all last week, we will not have a synchronous class tomorrow but instead have asked you all to register and attend any sessions of interests at the Rstudio global conference taking place tomorrow The link to register is here.\nThere are many interesting talks taking place - you can see the full program here. I have earmarked a few talks that are personally interesting to me that I think resonate with topics/issues we will address in the course around using data to make decisions with technology. These are listed below and marked the ones in red that are specifically on the topic of data visualization, which is a problem we will discuss next week.\nI would pay particular attention to the opening keynote talk by Hadley Wickham (the chief scientist of Rstudio and designer of the Tidyverse framework for data science in R, which includes the famed visualization package ggplot).\n\n\n\n\n\ntime\n\n\npresenter\n\n\ntitle\n\n\nurl\n\n\n11:00AM\n\n\nHadley Wickham\n\n\nMaintaining the house the tidyverse built\n\n\nhttps://global.rstudio.com/student/page/40521\n\n\n01:00PM\n\n\nKara Woo\n\n\nAlways look on the bright side of plots\n\n\nhttps://global.rstudio.com/student/page/40618\n\n\n02:19PM\n\n\nMegan Beckett\n\n\nAesthetically automated figure production\n\n\nhttps://global.rstudio.com/student/page/40627\n\n\n01:19PM\n\n\nSean Lopp\n\n\nR & Python: Going Steady\n\n\nhttps://global.rstudio.com/student/page/40638\n\n\n01:19PM\n\n\nNicole Kramer\n\n\nA New Paradigm for Multifigure, Coordinate-Based Plotting in R\n\n\nhttps://global.rstudio.com/student/page/40633\n\n\n02:00PM\n\n\nSophie Beiers\n\n\nTrial and Error in Data Viz at the ACLU\n\n\nhttps://global.rstudio.com/student/page/40642\n\n\n03:00PM\n\n\nJohn Burn-Murdoch\n\n\nReporting on and visualising the pandemic\n\n\nhttps://global.rstudio.com/student/page/40615\n\n\n06:20PM\n\n\nRiva Quiroga\n\n\nHow to do things with words: learning to program in R with a ‚Äúcommunicative approach‚Äù\n\n\nhttps://global.rstudio.com/student/page/40637\n\n\n05:00PM\n\n\nEmily Riederer\n\n\noRganization: How to make internal R packages part of your team\n\n\nhttps://global.rstudio.com/student/page/40607\n\n\n05:19PM\n\n\nMalcolm Barrett\n\n\nYou‚Äôre Already Ready: Zen and the Art of R Package Development\n\n\nhttps://global.rstudio.com/student/page/40621\n\n\n06:20PM\n\n\nAthanasia M. Mowinckel\n\n\nMake a package - Make some friends\n\n\nhttps://global.rstudio.com/student/page/40599\n\n\n06:25PM\n\n\nJohn Helveston\n\n\nUsing formr to create R-powered surveys with individualized feedback\n\n\nhttps://global.rstudio.com/student/page/40616\n\n\n06:35PM\n\n\nAlex Cookson\n\n\nThe Power of Great Datasets\n\n\nhttps://global.rstudio.com/student/page/40596\n\n\n05:00PM\n\n\nMax Kuhn\n\n\nWhat‚Äôs new in tidymodels?\n\n\nhttps://global.rstudio.com/student/page/40625\n\n\n05:16PM\n\n\nShirbi Ish-Shalom\n\n\nUsing R to Up Your Experimentation Game\n\n\nhttps://global.rstudio.com/student/page/40640\n\n\n06:23PM\n\n\nSimon Couch\n\n\ntidymodels/stacks, Or, In Preparation for Pesto: A Grammar for Stacked Ensemble Modeling\n\n\nhttps://global.rstudio.com/student/page/40641\n\n\n06:38PM\n\n\nAlan Feder\n\n\nCategorical Embeddings: New Ways to Simplify Complex Data\n\n\nhttps://global.rstudio.com/student/page/40595\n\n\n09:20PM\n\n\nEric Gunnar Cronstrom\n\n\nHow we made the switch: a case study on automating a complex report.\n\n\nhttps://global.rstudio.com/student/page/40608\n\n\n10:00PM\n\n\nRika\n\n\nFrom Zero to Hero: Best practices for setting up Rstudio Team in the Cloud\n\n\nhttps://global.rstudio.com/student/page/40636\n\n\n10:17PM\n\n\nDean Marchiori\n\n\nHow reproducible am I? A retrospective on a year of commercial data science projects in R\n\n\nhttps://global.rstudio.com/student/page/40606\n\n\n10:26PM\n\n\nCarson Sievert\n\n\nCustom theming in Shiny & R Markdown with bslib & thematic\n\n\nhttps://global.rstudio.com/student/page/40601\n\n\n09:18PM\n\n\nBarret Schloerke\n\n\nplumber + future: Async Web APIs\n\n\nhttps://global.rstudio.com/student/page/40600\n\n\n10:00PM\n\n\nNeal Richardson\n\n\nBigger Data With Ease Using Apache Arrow\n\n\nhttps://global.rstudio.com/student/page/40631\n\n\n10:19PM\n\n\nZJ\n\n\nEasy larger-than-RAM data manipulation with {disk.frame}\n\n\nhttps://global.rstudio.com/student/page/40647\n\n\n10:24PM\n\n\nGarrick Aden-Buie\n\n\nxaringan Playground: Using xaringan to learn web development\n\n\nhttps://global.rstudio.com/student/page/40609\n\n\n10:34PM\n\n\nLucy D‚ÄôAgostino McGowan\n\n\nDesigning Randomized Studies using Shiny\n\n\nhttps://global.rstudio.com/student/page/40620\n\n\n\n\n\n",
    "preview": "https://rstudio.com/assets/img/rstudio-global-with-date.jpg",
    "last_modified": "2021-01-20T15:50:26+00:00",
    "input_file": {}
  }
]
